# Princípios da teoria da aprendizagem profunda - uma abordagem utilizando a teoria efetiva 

Este texto tem por objetivo apresentar uma análise do capítulo 0 (zero) do livro “*The Principles of Deep Learning Theory*”. Ao apresentar as principais ideias e teorias primárias do aprendizado profundo, serão destacados os aspectos inovadores e fundamentais trazidos pelos autores. Esta análise busca descrever como esses conceitos contribuem para nosso entendimento das redes neurais profundas com foco na compreensão intuitiva em detrimento de cálculos formais. Por fim, será realizada uma reflexão e críticas obre as forças e limitações das abordagens e teorias discutidas, em comparação com outras ideias no campo do aprendizado profundo.

Investimentos em tecnologia permitiram aos sistemas de IA contar com bilhões de componentes primários para realizar tarefas complexas anteriormente reservadas às inteligências naturais como humanos. A IA se apoia no aprendizado profundo, usando redes neurais artificiais como modelo. Essas redes, compostas por blocos computacionais básicos chamados neurônios, são treinadas com dados reais para resolver problemas, diferentemente da programação tradicional. O poder do aprendizado profundo vem das redes neurais profundas, que transformam dados em representações úteis. Embora os modelos modernos de aprendizagem profunda sejam compostos por inúmeros componentes computacionais elementares, a descrição microscópica de como uma rede neural treinada calcula uma função a partir desses componentes já é bem conhecida. No entanto, como durante o treinamento esses componentes são ajustados de forma complexa e específica, a compreensão macroscópica do porquê a rede calcula uma função específica ainda é difícil. Com a complexidade das afinações e a diversidade de tarefas realizadas pelos neurônios, é desafiador utilizar a teoria matemática para entender completamente esses modelos.

A abordagem proposta pelos autores utiliza a **teoria efetiva**, que tem origem no campo da física teórica e se propõe a encontrar soluções simples para sistemas complicados com grande número de componentes. Essa ferramenta pode ser útil para a compreensão teórica de redes neurais profundas. Com essa abordagem, por exemplo, as leis da **termodinâmica** foram surgiram a partir da observação do comportamento estatístico coletivo de um grande número de partículas microscópicas, e posteriormente foram usadas para codificar a mecânica do vapor. Considerando que a física não faz distinção entre fenômenos naturais e artificiais, mas preocupa-se em fornecer um conjunto unificado de princípios que descrevam observações empíricas passadas e prevejam o resultado para experiências futuras, a teoria efetiva poderia realmente entender aprendizagem profunda.

Os autores definem uma **rede neural** como uma receita para calcular uma função, composto por várias unidades básicas chamadas **neurônios**. Cada neurônio recebe sinais de entrada, realiza uma combinação linear desses sinais ponderada por pesos específicos e aplica uma **função de ativação** para produzir um sinal de saída. Os neurônios são **organizados em camadas**, e **redes neurais profundas** consistem em várias camadas empilhadas sequencialmente. A rede neural é caracterizada pelos seus **parâmetros**, que incluem os **pesos** associados às conexões entre os neurônios e os **limiares de ativação** de cada neurônio.

Pensando em uma rede neural como uma função parametrizada, chamada **função de rede**, que depende de um conjunto de **entradas** e de um **vetor de parâmetros de alta dimensionalidade**, para que tal função seja útil, precisamos ajustar de alguma forma esse vetor de parâmetros de forma que o resultado função seja o mais próximo possível de um valor desejado, ou função alvo. Isso se chama **aproximação de função**. O refinamento desse vetor é feito ajustando a função de rede para os **dados de treinamento**, que são uma amostra dos dados observados da **função alvo**. O ajuste desses parâmetros é chamado **treinamento**, e o procedimento específico usado para ajustá-los é chamado de **algoritmo de aprendizagem**. Ao final desse processo obtemos uma **função de rede treinada**. O objetivo dos autores é nos levar a compreender o comportamento macroscópico função de rede a partir de uma descrição microscópica de princípios elementares da rede em termos destes **parâmetros treinados**. Além disso, também devemos entender como funciona o processo de aproximação da função de rede e avaliar como essa função usa os dados de treinamento para se aproximar da função alvo.

A fim de aplicar a abordagem da teoria efetiva, os autores buscam representar a função de rede treinada por uma expansão de Taylor em torno dos valores inicializados de seus parâmetros. Assim, ama vez resolvidos os problemas associados a essa representação, poderiam, em princípio, usar essa representação da série de Taylor para estudar a função de rede treinada. Mais especificamente, encontrariam uma distribuição sobre funções de rede treinadas que dependeriam, de forma simples, do algoritmo de aprendizagem e dos dados que utilizam para o treinamento.

Considerando os neurônios como componentes da rede, existem essencialmente duas maneiras principais pelas quais podemos fazer uma rede crescer em tamanho, aumentando sua largura ou a sua profundidade. Idealizando uma rede neural que possua limite de largura infinita, os autores chegam a uma função de rede treinada que é uma simples distribuição gaussiana com uma média diferente de zero, de forma que podem facilmente analisar as funções que tais redes estão computando. Estas simplificações são a consequência do **princípio da dispersão**. Por esse princípio, da perspectiva de qualquer neurônio específico, a entrada de um número infinito de sinais é tal que a **lei de nivelamento de grandes números** obscurece completamente muitos dos detalhes nos sinais. O resultado é que a **teoria efetiva** de muitas dessas redes de largura infinita leva a uma dispersão extrema na sua descrição, por exemplo, permitindo o truncamento da expansão de Taylor usada para representar a função de rede treinada.

No entanto essa representação ainda não é suficiente para descrever de forma macroscópica o comportamento da função de rede devido a uma incompatibilidade entre a descrição teórica e a observação prática para redes de mais de uma camada. Em particular, é empiricamente conhecido que a distribuição através de tais redes treinadas dependem das propriedades do algoritmo de aprendizagem usado para treiná-los. Do ponto de vista teórico, o problema com este limite é a eliminação dos pequenos detalhes de cada neurônio devido à consideração de um número infinito de sinais recebidos. Em particular, tal acumulação infinita elimina completamente as correlações sutis entre neurônios que são amplificadas ao longo do treinamento para aprendizagem de representação.

Com isso em mente, talvez o limite de largura infinita possa ser corrigido de forma que as correções se tornem pequenas quando a largura é grande. Para fazer isso, os autores utilizam a **teoria da perturbação**, assim como é utilizada na física para analisar sistemas interativos. Como resultado, a descrição da distribuição treinada será uma **distribuição quase gaussiana**. Essa distribuição incorpora as interações entre os neurônios, a dependência dos algoritmos de aprendizagem e inclui a representação de aprendizagem não trivial. Por isso, qualitativamente, esta teoria efetiva na ordem corresponde muito melhor às redes neurais do que a descrição de largura infinita, tornando-a muito mais útil, teoricamente, com um modelo mínimo para compreender a aprendizagem profunda. Como a maioria das redes de uso prático a relação profundidade/largura é razoavelmente pequena a **teoria efetiva de largura finita**, fornece um resultado mais preciso da saída da rede treinada. Estas são efetivamente redes profundas.
